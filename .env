# LLM Bridge for Claude Code Configuration

# API Keys (set at least one)
ANTHROPIC_API_KEY=
OPENAI_API_KEY=
GEMINI_API_KEY=

# Preferred Provider (ollama, openai, anthropic, google)
PREFERRED_PROVIDER=ollama

# Model Configuration
# For Ollama, use model names like: codellama:13b, llama3:8b, mistral:7b
BIG_MODEL=codellama:13b
SMALL_MODEL=codellama:7b

# Ollama Configuration
OLLAMA_API_BASE=http://localhost:11434

# Server Configuration
HOST=0.0.0.0
PORT=8083

# Logging Configuration
LOG_LEVEL=INFO
